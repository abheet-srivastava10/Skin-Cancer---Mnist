{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5368899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,Optimizer,Optimizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, MaxPooling2D, BatchNormalization, \\\n",
    "                        Permute, TimeDistributed, Bidirectional, GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2de4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"C:/Extra project/Skin Cancer/HAM10000_metadata.csv\"\n",
    "cancer = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d0de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer[\"path\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b476958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_folder = \"C:/Extra project/Skin Cancer/HAM10000_images_part_1\"\n",
    "part2_folder = \"C:/Extra project/Skin Cancer/HAM10000_images_part_2\"\n",
    "\n",
    "cancer.fillna({'age': np.mean(cancer['age'])}, inplace=True)\n",
    "image_paths = []\n",
    "for part in (\"part_1\", \"part_2\"):\n",
    "    image_paths += glob.glob(\"C:/Extra project/Skin Cancer/HAM10000_images_\" + part + \"/*\")\n",
    "image_ids_n_paths = {os.path.splitext(os.path.basename(path))[0]: path for path in image_paths}\n",
    "cancer['path'] = cancer['image_id'].map(image_ids_n_paths)\n",
    "labels = pd.get_dummies(cancer['dx']).iloc[:, :4].values  # Modify to keep only 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e2c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    # Implement your image loading and preprocessing logic here\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [90, 120])\n",
    "    image = image / 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5e6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_val_data = train_test_split(cancer, test_size=0.3, random_state=42)\n",
    "test_data, val_data = train_test_split(test_val_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_images = np.array([load_image(path) for path in train_data['path'].values])\n",
    "train_labels = pd.get_dummies(train_data['dx']).iloc[:, :4].values  # Modify to keep only 4 columns\n",
    "\n",
    "test_images = np.array([load_image(path) for path in test_data['path'].values])\n",
    "test_labels = pd.get_dummies(test_data['dx']).iloc[:, :4].values  # Modify to keep only 4 columns\n",
    "\n",
    "val_images = np.array([load_image(path) for path in val_data['path'].values])\n",
    "val_labels = pd.get_dummies(val_data['dx']).iloc[:, :4].values  # Modify to keep only 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57911bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 88, 118, 32)       896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 88, 118, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 44, 59, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 44, 59, 24)        6936      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 44, 59, 24)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 22, 29, 24)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               7840256   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,980,572\n",
      "Trainable params: 7,980,508\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Number of layers: 12\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(90, 120, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(24, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.summary()\n",
    "number_of_layers = len(model.layers)\n",
    "print(\"Number of layers:\", number_of_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4dac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b567c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\"),\n",
    "    tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\", save_best_only=True, filepath=\"./my_model\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f812b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - ETA: 0s - loss: 1458362.1250 - accuracy: 0.2310INFO:tensorflow:Assets written to: .\\my_model\\assets\n",
      "220/220 [==============================] - 126s 567ms/step - loss: 1458362.1250 - accuracy: 0.2310 - val_loss: 1094410.7500 - val_accuracy: 0.1211\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 194s 882ms/step - loss: 55878448.0000 - accuracy: 0.2351 - val_loss: 30020592.0000 - val_accuracy: 0.1211\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 194s 884ms/step - loss: 405766912.0000 - accuracy: 0.2372 - val_loss: 68249048.0000 - val_accuracy: 0.1211\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - ETA: 0s - loss: 1581678976.0000 - accuracy: 0.2399INFO:tensorflow:Assets written to: .\\my_model\\assets\n",
      "220/220 [==============================] - 214s 973ms/step - loss: 1581678976.0000 - accuracy: 0.2399 - val_loss: 195208160.0000 - val_accuracy: 0.8184\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 199s 905ms/step - loss: 3339095040.0000 - accuracy: 0.2361 - val_loss: 1460805888.0000 - val_accuracy: 0.0472\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 199s 906ms/step - loss: 5336521216.0000 - accuracy: 0.2341 - val_loss: 2603526400.0000 - val_accuracy: 0.1211\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=10, batch_size=32, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90fbe246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 13s 223ms/step - loss: 2645356800.0000 - accuracy: 0.1119 9s\n",
      "Test Loss:2645356800.0000\n",
      "Test Accuracy:0.11\n"
     ]
    }
   ],
   "source": [
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator().flow(test_images, test_labels, batch_size=32)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print('Test Loss:'+ \"%.4f\" % test_loss)\n",
    "print('Test Accuracy:'  + \"%.2f\" % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
